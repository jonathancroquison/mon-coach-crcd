import streamlit as st
import google.generativeai as genai
import time

# On essaie d'importer les prompts, sinon on utilise des valeurs par d√©faut
try:
    from prompts import PROMPT_CLIENT, PROMPT_COACH
except ImportError:
    PROMPT_CLIENT = "Tu es un client."
    PROMPT_COACH = "Analyse l'appel."

# --- 1. CONFIGURATION ---
st.set_page_config(page_title="Simulateur CRCD", layout="wide")

# Configuration de la cl√© Google Gemini
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.warning("‚ö†Ô∏è Cl√© API non trouv√©e. Configurez-la dans les 'Secrets' de Streamlit.")

# --- 2. FONCTIONS UTILES ---
def obtenir_reponse_gemini(message_utilisateur, historique):
    """Envoie la conversation √† Gemini et r√©cup√®re la r√©ponse"""
    try:
        # On pr√©pare le mod√®le
        model = genai.GenerativeModel('gemini-1.5-flash')
        
        # On construit l'historique pour Gemini
        # Gemini a besoin d'une liste altern√©e user/model
        history_gemini = []
        # On ajoute le prompt syst√®me comme premier message utilisateur (astuce pour Gemini Flash)
        history_gemini.append({"role": "user", "parts": [PROMPT_CLIENT]})
        history_gemini.append({"role": "model", "parts": ["Compris, je joue le r√¥le du client."]})
        
        for msg in historique:
            if msg["role"] != "system":
                role_gemini = "user" if msg["role"] == "user" else "model"
                history_gemini.append({"role": role_gemini, "parts": [msg["content"]]})
        
        chat = model.start_chat(history=history_gemini)
        response = chat.send_message(message_utilisateur)
        return response.text
    except Exception as e:
        return f"D√©sol√©, une erreur technique est survenue : {e}"

def analyse_coach(transcription):
    """Demande √† Gemini d'analyser l'appel"""
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        prompt_complet = PROMPT_COACH + "\n\nTRANSCRIPTION DE L'APPEL:\n" + transcription
        response = model.generate_content(prompt_complet)
        return response.text
    except Exception as e:
        return f"Erreur lors de l'analyse du coach : {e}"

# --- 3. M√âMOIRE DE L'APPLICATION ---
if "messages" not in st.session_state:
    st.session_state.messages = [] 

if "appel_en_cours" not in st.session_state:
    st.session_state.appel_en_cours = False

if "start_time" not in st.session_state:
    st.session_state.start_time = None

# --- 4. INTERFACE (SIDEBAR) ---
with st.sidebar:
    st.title("üéß Coach CRCD")
    st.markdown("Moteur : **Google Gemini** (Gratuit)")
    
    if st.button("üü¢ D√âCROCHER L'APPEL"):
        st.session_state.appel_en_cours = True
        st.session_state.start_time = time.time()
        st.session_state.messages = [] # Reset de la conversation
        st.session_state.analyse_demandee = False
        st.rerun()

    if st.session_state.appel_en_cours and st.session_state.start_time:
        duree = int(time.time() - st.session_state.start_time)
        st.metric("Temps d'appel", f"{duree} sec")

    if st.button("üî¥ RACCROCHER & ANALYSER"):
        st.session_state.appel_en_cours = False
        st.session_state.analyse_demandee = True
        st.rerun()

# --- 5. ZONE DE CHAT ---
st.header("Simulation d'appel")

# Affichage des messages
for msg in st.session_state.messages:
    if msg["role"] != "system":
        icone = "üßë‚Äçüíª" if msg["role"] == "user" else "üë§"
        with st.chat_message(msg["role"], avatar=icone):
            st.write(msg["content"])

# Zone de saisie
if st.session_state.appel_en_cours:
    reponse_apprenti = st.chat_input("Votre r√©ponse...")
    if reponse_apprenti:
        # 1. Afficher message apprenti
        st.session_state.messages.append({"role": "user", "content": reponse_apprenti})
        with st.chat_message("user", avatar="üßë‚Äçüíª"):
            st.write(reponse_apprenti)

        # 2. R√©ponse IA (Gemini)
        with st.spinner("Le client r√©pond..."):
            reponse_ia = obtenir_reponse_gemini(reponse_apprenti, st.session_state.messages[:-1])
            
            st.session_state.messages.append({"role": "assistant", "content": reponse_ia})
            with st.chat_message("assistant", avatar="üë§"):
                st.write(reponse_ia)

# --- 6. FEEDBACK COACH ---
if hasattr(st.session_state, 'analyse_demandee') and st.session_state.analyse_demandee:
    st.divider()
    st.subheader("üìù Analyse du Coach")
    with st.spinner("Le coach relit la conversation..."):
        # On compile le texte pour le coach
        texte_appel = ""
        for msg in st.session_state.messages:
            role = "Conseiller" if msg["role"] == "user" else "Client"
            texte_appel += f"{role}: {msg['content']}\n"
            
        feedback = analyse_coach(texte_appel)
        st.info(feedback)
        # On d√©sactive la demande pour √©viter que √ßa recharge en boucle
        st.session_state.analyse_demandee = False
