
import streamlit as st
import google.generativeai as genai
import time
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder
import io

# --- IMPORTATION DES SC√âNARIOS ---
try:
    from prompts import SCENARIOS
except ImportError:
    st.error("Erreur : Le fichier prompts.py est introuvable.")
    st.stop()

# --- CONFIGURATION DE LA PAGE ---
st.set_page_config(page_title="Simulateur CRCD Audio", layout="wide", page_icon="üéß")

# --- CSS POUR LE STYLE ---
st.markdown("""
<style>
    .stButton>button { width: 100%; border-radius: 10px; height: 3em; }
    .audio-player { margin-top: 10px; }
</style>
""", unsafe_allow_html=True)

# --- CONNEXION IA ---
if "GOOGLE_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
else:
    st.warning("‚ö†Ô∏è Cl√© API manquante. Configurez-la dans les Secrets.")

# --- FONCTIONS ---

def transcrire_audio(audio_bytes):
    """
    Envoie l'audio √† Gemini pour transcription.
    CORRECTION : Utilise le format WebM (natif navigateur) pour √©viter les erreurs.
    """
    try:
        model = genai.GenerativeModel('gemini-2.0-flash')
        
        prompt_transcription = """
        Tu es un expert en transcription phon√©tique.
        Ta t√¢che : Convertir cet audio en texte fran√ßais.
        R√®gles IMP√âRATIVES :
        1. √âcris EXACTEMENT ce que tu entends.
        2. Si le son est inaudible, s'il n'y a que du bruit de fond ou du silence, R√âPONDS UNIQUEMENT PAR "..." (trois points).
        3. N'invente AUCUN mot. Ne compl√®te pas les phrases.
        """
        
        # On force la temp√©rature √† 0 pour la fid√©lit√©
        config = genai.types.GenerationConfig(temperature=0.0)
        
        # CORRECTION : On pr√©cise le mime_type audio/webm
        response = model.generate_content(
            [prompt_transcription, {"mime_type": "audio/webm", "data": audio_bytes}],
            generation_config=config
        )
        
        texte = response.text.strip()
        if texte == "..." or texte == "":
            return None
        return texte

    except Exception as e:
        st.error(f"Erreur technique lors de la transcription : {e}")
        return None

def parler(texte, langue='fr'):
    """Transforme le texte en fichier audio MP3 via Google TTS"""
    try:
        tts = gTTS(text=texte, lang=langue, slow=False)
        audio_fp = io.BytesIO()
        tts.write_to_fp(audio_fp)
        return audio_fp
    except Exception as e:
        return None

def obtenir_reponse_gemini(message_utilisateur, historique, prompt_systeme):
    try:
        model = genai.GenerativeModel('gemini-2.0-flash')
        
        # Construction de l'historique pour Gemini
        history_gemini = []
        history_gemini.append({"role": "user", "parts": [prompt_systeme]})
        history_gemini.append({"role": "model", "parts": ["C'est compris, je rentre dans le personnage."]})
        
        for msg in historique:
            if msg["role"] != "system":
                role_gemini = "user" if msg["role"] == "user" else "model"
                history_gemini.append({"role": role_gemini, "parts": [msg["content"]]})
        
        chat = model.start_chat(history=history_gemini)
        response = chat.send_message(message_utilisateur)
        return response.text
    except Exception as e:
        return f"Erreur IA : {e}"

def analyse_coach(transcription, prompt_coach):
    try:
        model = genai.GenerativeModel('gemini-2.0-flash')
        full_prompt = prompt_coach + "\n\nTRANSCRIPTION DE L'APPEL:\n" + transcription
        response = model.generate_content(full_prompt)
        return response.text
    except Exception as e:
        return f"Erreur Coach : {e}"

# --- GESTION DE L'√âTAT (SESSION STATE) ---
if "page" not in st.session_state: st.session_state.page = "notice"
if "selected_scenario" not in st.session_state: st.session_state.selected_scenario = None
if "messages" not in st.session_state: st.session_state.messages = [] 
if "appel_en_cours" not in st.session_state: st.session_state.appel_en_cours = False
if "start_time" not in st.session_state: st.session_state.start_time = None
if "last_audio_id" not in st.session_state: st.session_state.last_audio_id = None

# =========================================================
# √âCRAN 1 : LA NOTICE D'USAGE
# =========================================================
if st.session_state.page == "notice":
    st.title("üéß Coach CRCD - Mode Vocal üéôÔ∏è")
    st.info("Syst√®me audio connect√© et pr√™t.")
    
    with st.expander("üìñ COMMENT UTILISER LA VOIX ?", expanded=True):
        st.markdown("""
        **Instructions :**
        1. Cliquez sur **"üî¥ Enregistrer"** (Barre lat√©rale).
        2. Parlez **distinctement**.
        3. Cliquez sur **"‚èπÔ∏è Envoyer"** (Stop).
        4. Attendez que votre texte apparaisse.
        """)
        
    if st.button("JE SUIS PR√äT - ACC√âDER AUX SC√âNARIOS ‚û°Ô∏è"):
        st.session_state.page = "choix_scenario"
        st.rerun()

# =========================================================
# √âCRAN 2 : LE CHOIX DES AVATARS
# =========================================================
elif st.session_state.page == "choix_scenario":
    st.title("Choisis ton client du jour")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.header("Avatar 1")
        st.info(f"üë∂ **{SCENARIOS['SCENARIO_1']['titre']}**")
        st.write("Travail sur l'Identification & la Trame.")
        if st.button("Choisir Th√©o"):
            st.session_state.selected_scenario = SCENARIOS["SCENARIO_1"]
            st.session_state.page = "simulation"
            st.rerun()

    with col2:
        st.header("Avatar 2")
        st.warning(f"üò§ **{SCENARIOS['SCENARIO_2']['titre']}**")
        st.write("Travail sur la R√©tention & Gestion de conflit.")
        if st.button("Choisir Sarah"):
            st.session_state.selected_scenario = SCENARIOS["SCENARIO_2"]
            st.session_state.page = "simulation"
            st.rerun()

    with col3:
        st.header("Avatar 3")
        st.error(f"üíº **{SCENARIOS['SCENARIO_3']['titre']}**")
        st.write("Travail sur la Vente Additionnelle.")
        if st.button("Choisir Marc"):
            st.session_state.selected_scenario = SCENARIOS["SCENARIO_3"]
            st.session_state.page = "simulation"
            st.rerun()
            
    if st.button("‚¨ÖÔ∏è Retour"):
        st.session_state.page = "notice"
        st.rerun()

# =========================================================
# √âCRAN 3 : LA SIMULATION (CHAT & VOIX)
# =========================================================
elif st.session_state.page == "simulation":
    scenario = st.session_state.selected_scenario
    
    # --- SIDEBAR DE CONTR√îLE ---
    with st.sidebar:
        st.title(f"{scenario['image']} Appel en cours")
        st.markdown(f"**{scenario['titre']}**")
        
        if not st.session_state.appel_en_cours:
            if st.button("üü¢ D√âCROCHER L'APPEL"):
                st.session_state.appel_en_cours = True
                st.session_state.start_time = time.time()
                st.session_state.messages = []
                st.session_state.analyse_demandee = False
                st.rerun()
        else:
            duree = int(time.time() - st.session_state.start_time)
            st.metric("‚è±Ô∏è DMT", f"{duree} sec")
            
            st.markdown("---")
            st.write("**üéôÔ∏è PARLER AU CLIENT :**")
            
            # --- BOUTON MICROPHONE CORRIG√â (WEBM) ---
            audio_data = mic_recorder(
                start_prompt="üî¥ Enregistrer (Parlez fort)",
                stop_prompt="‚èπÔ∏è Envoyer",
                just_once=True,
                key='recorder',
                format="webm" # <--- IMPORTANT : Format WebM pour √©viter les erreurs
            )
            
            st.markdown("---")
            if st.button("üî¥ RACCROCHER & ANALYSER"):
                st.session_state.appel_en_cours = False
                st.session_state.analyse_demandee = True
                st.rerun()
        
        st.markdown("---")
        if st.button("üîô Changer de sc√©nario"):
            st.session_state.page = "choix_scenario"
            st.session_state.appel_en_cours = False
            st.rerun()

    # --- ZONE PRINCIPALE (CHAT) ---
    st.header(f"üìû {scenario['titre']}")

    # 1. Affichage historique
    for msg in st.session_state.messages:
        if msg["role"] != "system":
            with st.chat_message(msg["role"], avatar=("üßë‚Äçüíª" if msg["role"] == "user" else scenario['image'])):
                st.write(msg["content"])
                if "audio" in msg and msg["audio"] is not None:
                    st.audio(msg["audio"], format="audio/mp3")

    # 2. LOGIQUE MICROPHONE
    if st.session_state.appel_en_cours and audio_data is not None:
        current_audio_id = audio_data['id']
        if current_audio_id != st.session_state.last_audio_id:
            st.session_state.last_audio_id = current_audio_id
            
            with st.spinner("Transcription de votre voix..."):
                # On envoie les bytes directement (format WebM)
                texte_apprenant = transcrire_audio(audio_data['bytes'])
            
            if texte_apprenant:
                st.session_state.messages.append({"role": "user", "content": texte_apprenant})
                st.rerun()
            else:
                st.toast("‚ö†Ô∏è Audio non compris ou silencieux.", icon="üîá")

    # 3. LOGIQUE CLAVIER
    if st.session_state.appel_en_cours:
        reponse_texte = st.chat_input("Ou √©crivez votre r√©ponse ici...")
        if reponse_texte:
            st.session_state.messages.append({"role": "user", "content": reponse_texte})
            st.rerun()

    # 4. R√âPONSE IA
    if st.session_state.messages and st.session_state.messages[-1]["role"] == "user" and st.session_state.appel_en_cours:
        with st.chat_message("assistant", avatar=scenario['image']):
            with st.spinner(f"{scenario['titre'].split(':')[1]} r√©fl√©chit..."):
                rep_ia = obtenir_reponse_gemini(
                    st.session_state.messages[-1]["content"], 
                    st.session_state.messages[:-1],
                    scenario['client_prompt']
                )
                
                audio_file = parler(rep_ia)
                st.write(rep_ia)
                if audio_file:
                    st.audio(audio_file, format='audio/mp3', start_time=0)
        
        st.session_state.messages.append({"role": "assistant", "content": rep_ia, "audio": audio_file})

    # 5. FEEDBACK COACH & T√âL√âCHARGEMENT
    if hasattr(st.session_state, 'analyse_demandee') and st.session_state.analyse_demandee:
        st.divider()
        st.subheader("üìù Rapport du Coach")
        
        with st.spinner("Le coach analyse votre appel..."):
            txt_conversation = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages if m['role']!='system'])
            analyse_resultat = analyse_coach(txt_conversation, scenario['coach_prompt'])
            
            st.info(analyse_resultat)
            
            # Cr√©ation du fichier Bilan
            rapport_complet = f"""
            BILAN DE FORMATION CRCD
            Date : {time.strftime("%d/%m/%Y √† %H:%M")}
            Sc√©nario : {scenario['titre']}
            DMT : {int(time.time() - st.session_state.start_time) if st.session_state.start_time else 0} sec
            
            --- ANALYSE ---
            {analyse_resultat}
            
            --- TRANSCRIPTION ---
            {txt_conversation}
            """
            
            st.download_button(
                label="üì• T√âL√âCHARGER MON BILAN (TXT)",
                data=rapport_complet,
                file_name=f"Bilan_{scenario['titre'].split(':')[0].strip()}.txt",
                mime="text/plain"
            )
            
            st.session_state.analyse_demandee = False
